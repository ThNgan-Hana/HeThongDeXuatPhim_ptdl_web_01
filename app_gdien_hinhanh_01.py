import streamlit as st
import pandas as pd
import numpy as np
import ast
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
import re

# ==============================================================================
# 0. C·∫§U H√åNH TRANG & CSS (PH·∫¶N QUAN TR·ªåNG ƒê·ªÇ GIAO DI·ªÜN ƒê·∫∏P)
# ==============================================================================
st.set_page_config(
    page_title="Cinematch - G·ª£i √Ω phim",
    page_icon="üçø",
    layout="wide",
    initial_sidebar_state="expanded"
)


def inject_custom_css():
    st.markdown("""
    <style>
    /* 1. N·ªÄN CHUY·ªÇN M√ÄU (GRADIENT BACKGROUND) */
    .stApp {
        background: linear-gradient(135deg, #0f0c29 0%, #302b63 50%, #24243e 100%);
        color: #ffffff;
    }

    /* 2. T√ôY CH·ªàNH THANH SIDEBAR */
    section[data-testid="stSidebar"] {
        background-color: rgba(0, 0, 0, 0.2);
        backdrop-filter: blur(10px);
        border-right: 1px solid rgba(255, 255, 255, 0.1);
    }

    /* 3. HI·ªÜU ·ª®NG CARD (TH·∫∫ PHIM) */
    .movie-card-container {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 15px;
        padding: 20px;
        border: 1px solid rgba(255, 255, 255, 0.1);
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    .movie-card-container:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 20px rgba(0, 0, 0, 0.5);
        border: 1px solid #E50914; /* Vi·ªÅn ƒë·ªè Netflix khi hover */
    }

    /* 4. T√ôY CH·ªàNH N√öT B·∫§M (BUTTONS) */
    .stButton > button {
        background: linear-gradient(90deg, #E50914 0%, #ff6b6b 100%);
        color: white;
        border: none;
        border-radius: 25px;
        font-weight: bold;
        padding: 0.5rem 1rem;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        transform: scale(1.05);
        box-shadow: 0 0 15px rgba(229, 9, 20, 0.6);
    }

    /* N√∫t ph·ª• (Secondary) */
    button[kind="secondary"] {
        background: transparent !important;
        border: 1px solid rgba(255,255,255,0.5) !important;
    }

    /* 5. TI√äU ƒê·ªÄ & CH·ªÆ */
    h1, h2, h3 {
        font-family: 'Helvetica Neue', sans-serif;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.5);
    }
    h1 {
        background: -webkit-linear-gradient(#eee, #999);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }

    /* 6. INPUT FIELDS */
    .stTextInput input, .stSelectbox div[data-baseweb="select"] {
        background-color: rgba(255, 255, 255, 0.1) !important;
        color: white !important;
        border-radius: 10px;
        border: 1px solid rgba(255, 255, 255, 0.2);
    }

    /* Ch·ªânh ·∫£nh trong card cho ƒë·ªÅu nhau */
    div[data-testid="stImage"] img {
        border-radius: 10px;
        object-fit: cover;
        width: 100%;
        height: 350px !important; /* C·ªë ƒë·ªãnh chi·ªÅu cao ·∫£nh ƒë·ªÉ grid ƒë·ªÅu */
    }

    /* ·∫®n Decoration m·∫∑c ƒë·ªãnh c·ªßa Streamlit */
    header {visibility: hidden;}
    footer {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)


# G·ªçi h√†m CSS ngay ƒë·∫ßu
inject_custom_css()

# ==============================================================================
# 1. C·∫§U H√åNH BI·∫æN TO√ÄN C·ª§C
# ==============================================================================

USER_DATA_FILE = "danh_sach_nguoi_dung_moi.csv"
MOVIE_DATA_FILE = "data_phim_full_images.csv"  # ƒê√£ c·∫≠p nh·∫≠t file m·ªõi
GUEST_USER = "Guest_ZeroClick"

if 'logged_in_user' not in st.session_state: st.session_state['logged_in_user'] = None
if 'auth_mode' not in st.session_state: st.session_state['auth_mode'] = 'login'
if 'last_profile_recommendations' not in st.session_state: st.session_state[
    'last_profile_recommendations'] = pd.DataFrame()
if 'show_profile_plot' not in st.session_state: st.session_state['show_profile_plot'] = False


# ==============================================================================
# 2. H√ÄM X·ª¨ L√ù D·ªÆ LI·ªÜU
# ==============================================================================

@st.cache_data
def load_data(file_path):
    try:
        return pd.read_csv(file_path).fillna("")
    except FileNotFoundError:
        st.error(f"‚ö†Ô∏è L·ªñI: Kh√¥ng t√¨m th·∫•y file '{file_path}'. H√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ upload file n√†y.")
        return pd.DataFrame()


def parse_genres(genre_string):
    if not isinstance(genre_string, str) or not genre_string: return set()
    genres = [g.strip().replace('"', '') for g in genre_string.split(',')]
    return set(genres)


@st.cache_resource
def load_and_preprocess_static_data():
    try:
        df_movies = load_data(MOVIE_DATA_FILE)
        if df_movies.empty: return pd.DataFrame(), np.array([[]]), []

        df_movies.columns = [col.strip() for col in df_movies.columns]

        # Ki·ªÉm tra c√°c c·ªôt b·∫Øt bu·ªôc
        required_columns = ["ƒê·∫°o di·ªÖn", "Di·ªÖn vi√™n ch√≠nh", "Th·ªÉ lo·∫°i phim", "T√™n phim"]
        missing_cols = [col for col in required_columns if col not in df_movies.columns]
        if missing_cols:
            st.error(f"D·ªØ li·ªáu thi·∫øu c√°c c·ªôt quan tr·ªçng: {missing_cols}")
            return pd.DataFrame(), np.array([[]]), []

        # Content-Based Features
        # X·ª≠ l√Ω fillna cho ch·∫Øc ch·∫Øn chu·ªói
        df_movies["combined_features"] = (
                df_movies["ƒê·∫°o di·ªÖn"].astype(str) + " " +
                df_movies["Di·ªÖn vi√™n ch√≠nh"].astype(str) + " " +
                df_movies["Th·ªÉ lo·∫°i phim"].astype(str)
        )

        # X·ª¨ L√ù NG√îN NG·ªÆ
        vectorizer = TfidfVectorizer(stop_words='english')
        tfidf_matrix = vectorizer.fit_transform(df_movies["combined_features"])
        cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)

        # Popularity Normalization
        if 'ƒê·ªô ph·ªï bi·∫øn' in df_movies.columns:
            df_movies['ƒê·ªô ph·ªï bi·∫øn'] = pd.to_numeric(df_movies['ƒê·ªô ph·ªï bi·∫øn'], errors='coerce')
            mean_popularity = df_movies['ƒê·ªô ph·ªï bi·∫øn'].mean() if not df_movies['ƒê·ªô ph·ªï bi·∫øn'].empty else 0
            df_movies['ƒê·ªô ph·ªï bi·∫øn'] = df_movies['ƒê·ªô ph·ªï bi·∫øn'].fillna(mean_popularity)
            scaler = MinMaxScaler()
            df_movies["popularity_norm"] = scaler.fit_transform(df_movies[["ƒê·ªô ph·ªï bi·∫øn"]])
        else:
            df_movies["popularity_norm"] = 0.5  # Default

        # Genre & Recency
        df_movies['parsed_genres'] = df_movies['Th·ªÉ lo·∫°i phim'].apply(parse_genres)
        if 'NƒÉm ph√°t h√†nh' in df_movies.columns:
            # X·ª≠ l√Ω nƒÉm c√≥ th·ªÉ l·∫´n k√Ω t·ª±
            df_movies['year_numeric'] = pd.to_numeric(df_movies['NƒÉm ph√°t h√†nh'], errors='coerce').fillna(0).astype(int)
            current_year = 2025
            df_movies['recency_score'] = df_movies['year_numeric'].apply(
                lambda x: 1.0 if x >= current_year - 1 else (0.8 if x >= current_year - 5 else 0.5))
        else:
            df_movies['year_numeric'] = 0
            df_movies['recency_score'] = 0.5

        all_genres = set()
        for genres_str in df_movies['Th·ªÉ lo·∫°i phim']:
            if genres_str:
                parts = [g.strip() for g in str(genres_str).split(',')]
                all_genres.update(parts)
        sorted_genres = sorted(list(all_genres))

        return df_movies, cosine_sim_matrix, sorted_genres
    except Exception as e:
        st.error(f"L·ªñI X·ª¨ L√ù DATA: {e}")
        return pd.DataFrame(), np.array([[]]), []


def initialize_user_data():
    if 'df_users' not in st.session_state:
        try:
            df_users = load_data(USER_DATA_FILE)
            if not df_users.empty:
                df_users.columns = [col.strip() for col in df_users.columns]
                if 'ID' in df_users.columns:
                    df_users['ID'] = pd.to_numeric(df_users['ID'], errors='coerce')
                    df_users = df_users.dropna(subset=['ID'])
                if 'Th·ªÉ lo·∫°i y√™u th√≠ch' not in df_users.columns: df_users['Th·ªÉ lo·∫°i y√™u th√≠ch'] = ""
            else:
                df_users = pd.DataFrame(columns=['ID', 'T√™n ng∆∞·ªùi d√πng', '5 phim coi g·∫ßn nh·∫•t', 'Phim y√™u th√≠ch nh·∫•t',
                                                 'Th·ªÉ lo·∫°i y√™u th√≠ch'])
        except Exception:
            df_users = pd.DataFrame(
                columns=['ID', 'T√™n ng∆∞·ªùi d√πng', '5 phim coi g·∫ßn nh·∫•t', 'Phim y√™u th√≠ch nh·∫•t', 'Th·ªÉ lo·∫°i y√™u th√≠ch'])
        st.session_state['df_users'] = df_users
    return st.session_state['df_users']


def get_unique_movie_titles(df_movies):
    if 'T√™n phim' in df_movies.columns: return df_movies['T√™n phim'].dropna().unique().tolist()
    return []


# ==============================================================================
# 3. HELPER HI·ªÇN TH·ªä (QUAN TR·ªåNG: RENDER MOVIE CARD V·ªöI ·∫¢NH)
# ==============================================================================

def display_movie_grid(df_result, title="K·∫øt qu·∫£ g·ª£i √Ω"):
    """H√†m hi·ªÉn th·ªã danh s√°ch phim d·∫°ng l∆∞·ªõi (Grid) ƒë·∫πp m·∫Øt v·ªõi ·∫£nh Poster"""
    st.markdown(f"### {title}")

    # Chia l∆∞·ªõi 3 c·ªôt (t√πy ch·ªânh responsive)
    cols = st.columns(3)

    for index, (i, row) in enumerate(df_result.iterrows()):
        col = cols[index % 3]  # Xoay v√≤ng qua 3 c·ªôt
        with col:
            # Container t·∫°o khung card
            with st.container(border=True):
                # --- PH·∫¶N HI·ªÇN TH·ªä ·∫¢NH ---
                poster_url = row.get('Link Poster', '')

                # Ki·ªÉm tra link ·∫£nh c√≥ h·ª£p l·ªá kh√¥ng
                has_image = False
                if isinstance(poster_url, str) and poster_url.startswith('http'):
                    try:
                        st.image(poster_url, use_container_width=True)
                        has_image = True
                    except:
                        pass  # N·∫øu l·ªói load ·∫£nh th√¨ fallback xu·ªëng d∆∞·ªõi

                if not has_image:
                    # N·∫øu kh√¥ng c√≥ ·∫£nh ho·∫∑c l·ªói, hi·ªÉn th·ªã avatar m√†u
                    random_color = f"hsl({np.random.randint(0, 360)}, 60%, 25%)"
                    st.markdown(f"""
                    <div style="background-color: {random_color}; padding: 40px; border-radius: 10px; text-align: center; margin-bottom: 10px;">
                        <div style="font-size: 50px;">üé¨</div>
                    </div>
                    """, unsafe_allow_html=True)

                # T√™n phim
                st.markdown(f"#### {row['T√™n phim']}")
                st.caption(f"üìÖ NƒÉm: **{row.get('NƒÉm ph√°t h√†nh', 'N/A')}**")

                # Th·ªÉ lo·∫°i d·∫°ng Tags
                genres_str = str(row.get('Th·ªÉ lo·∫°i phim', ''))
                genres = [g.strip() for g in genres_str.split(',')]
                genre_html = "".join([
                    f"<span style='background:rgba(255,255,255,0.1); padding:2px 8px; border-radius:12px; font-size:0.8em; margin-right:5px;'>{g}</span>"
                    for g in genres[:3]])
                st.markdown(f"<div style='margin-bottom:10px;'>{genre_html}</div>", unsafe_allow_html=True)

                # ƒêi·ªÉm s·ªë
                score = row.get('final_score', row.get('Similarity_Score', row.get('weighted_score', 0)))
                # Normalize score ƒë·ªÉ hi·ªÉn th·ªã progress bar (gi·∫£ s·ª≠ max 10 ho·∫∑c max theo logic)
                display_score = score
                if display_score > 10: display_score = 10  # Cap visual

                st.markdown(f"""
                <div style="display:flex; justify-content:space-between; align-items:center; font-size:0.9em; margin-top:5px;">
                    <span>